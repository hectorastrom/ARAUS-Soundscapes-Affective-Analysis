{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T-Testing ARAUS\n",
    "\n",
    "We'll start by setting up our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "749 unique participants\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant</th>\n",
       "      <th>fold_r</th>\n",
       "      <th>soundscape</th>\n",
       "      <th>masker</th>\n",
       "      <th>smr</th>\n",
       "      <th>stimulus_index</th>\n",
       "      <th>time_taken</th>\n",
       "      <th>is_attention</th>\n",
       "      <th>pleasant</th>\n",
       "      <th>eventful</th>\n",
       "      <th>...</th>\n",
       "      <th>M04000_0_r</th>\n",
       "      <th>M05000_0_r</th>\n",
       "      <th>M06300_0_r</th>\n",
       "      <th>M08000_0_r</th>\n",
       "      <th>M10000_0_r</th>\n",
       "      <th>M12500_0_r</th>\n",
       "      <th>M16000_0_r</th>\n",
       "      <th>M20000_0_r</th>\n",
       "      <th>Leq_L_r</th>\n",
       "      <th>Leq_R_r</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ARAUS_00009</td>\n",
       "      <td>4</td>\n",
       "      <td>R0087_segment_binaural_44100_1.wav</td>\n",
       "      <td>silence_00004.wav</td>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>35.592</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>46.13</td>\n",
       "      <td>40.68</td>\n",
       "      <td>38.51</td>\n",
       "      <td>33.42</td>\n",
       "      <td>25.83</td>\n",
       "      <td>21.02</td>\n",
       "      <td>20.67</td>\n",
       "      <td>22.70</td>\n",
       "      <td>73.761966</td>\n",
       "      <td>75.353091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ARAUS_00021</td>\n",
       "      <td>1</td>\n",
       "      <td>R0081_segment_binaural_44100_2.wav</td>\n",
       "      <td>traffic_00029.wav</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>37.439</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>47.66</td>\n",
       "      <td>42.56</td>\n",
       "      <td>41.86</td>\n",
       "      <td>42.69</td>\n",
       "      <td>37.15</td>\n",
       "      <td>36.50</td>\n",
       "      <td>30.99</td>\n",
       "      <td>19.27</td>\n",
       "      <td>74.202644</td>\n",
       "      <td>73.493800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ARAUS_00021</td>\n",
       "      <td>1</td>\n",
       "      <td>R0046_segment_binaural_44100_2.wav</td>\n",
       "      <td>bird_00047.wav</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>37.833</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>43.73</td>\n",
       "      <td>39.67</td>\n",
       "      <td>35.29</td>\n",
       "      <td>33.46</td>\n",
       "      <td>27.51</td>\n",
       "      <td>19.27</td>\n",
       "      <td>18.67</td>\n",
       "      <td>12.37</td>\n",
       "      <td>67.246896</td>\n",
       "      <td>68.127026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ARAUS_00021</td>\n",
       "      <td>1</td>\n",
       "      <td>R0080_segment_binaural_44100_2.wav</td>\n",
       "      <td>traffic_00006.wav</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>33.782</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>44.57</td>\n",
       "      <td>43.30</td>\n",
       "      <td>43.81</td>\n",
       "      <td>36.82</td>\n",
       "      <td>31.24</td>\n",
       "      <td>28.05</td>\n",
       "      <td>23.03</td>\n",
       "      <td>17.66</td>\n",
       "      <td>67.395837</td>\n",
       "      <td>68.006605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ARAUS_00021</td>\n",
       "      <td>1</td>\n",
       "      <td>R0115_segment_binaural_44100_1.wav</td>\n",
       "      <td>bird_00059.wav</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>37.663</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>37.86</td>\n",
       "      <td>31.16</td>\n",
       "      <td>25.78</td>\n",
       "      <td>19.90</td>\n",
       "      <td>16.79</td>\n",
       "      <td>13.98</td>\n",
       "      <td>14.23</td>\n",
       "      <td>12.36</td>\n",
       "      <td>65.505416</td>\n",
       "      <td>66.575806</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 160 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   participant  fold_r                          soundscape             masker  \\\n",
       "0  ARAUS_00009       4  R0087_segment_binaural_44100_1.wav  silence_00004.wav   \n",
       "1  ARAUS_00021       1  R0081_segment_binaural_44100_2.wav  traffic_00029.wav   \n",
       "2  ARAUS_00021       1  R0046_segment_binaural_44100_2.wav     bird_00047.wav   \n",
       "3  ARAUS_00021       1  R0080_segment_binaural_44100_2.wav  traffic_00006.wav   \n",
       "4  ARAUS_00021       1  R0115_segment_binaural_44100_1.wav     bird_00059.wav   \n",
       "\n",
       "   smr  stimulus_index  time_taken  is_attention  pleasant  eventful  ...  \\\n",
       "0    3              28      35.592             0         5         5  ...   \n",
       "1    0               4      37.439             0         5         5  ...   \n",
       "2    3               8      37.833             0         5         5  ...   \n",
       "3    3              11      33.782             0         5         5  ...   \n",
       "4    0              12      37.663             0         5         5  ...   \n",
       "\n",
       "   M04000_0_r  M05000_0_r  M06300_0_r  M08000_0_r  M10000_0_r  M12500_0_r  \\\n",
       "0       46.13       40.68       38.51       33.42       25.83       21.02   \n",
       "1       47.66       42.56       41.86       42.69       37.15       36.50   \n",
       "2       43.73       39.67       35.29       33.46       27.51       19.27   \n",
       "3       44.57       43.30       43.81       36.82       31.24       28.05   \n",
       "4       37.86       31.16       25.78       19.90       16.79       13.98   \n",
       "\n",
       "   M16000_0_r  M20000_0_r    Leq_L_r    Leq_R_r  \n",
       "0       20.67       22.70  73.761966  75.353091  \n",
       "1       30.99       19.27  74.202644  73.493800  \n",
       "2       18.67       12.37  67.246896  68.127026  \n",
       "3       23.03       17.66  67.395837  68.006605  \n",
       "4       14.23       12.36  65.505416  66.575806  \n",
       "\n",
       "[5 rows x 160 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "file_path = \"datasets/ARAUS_precleaned.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "print(len(data[\"participant\"].unique()), \"unique participants\")\n",
    "\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we define all the values we will use for our analysis\n",
    "\n",
    "### DEFINITIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data compressed from 32232 entries to 15729 entries in the merged table.\n",
      "Average grouping size: 2.049 soundscapes.\n",
      "Largest group merger count: 136.0 soundscapes\n",
      "\n",
      "Group size distribution:\n",
      "merge_count\n",
      "1      7696\n",
      "2      4600\n",
      "3      3048\n",
      "4        32\n",
      "5       112\n",
      "19       16\n",
      "20      129\n",
      "21       82\n",
      "22        7\n",
      "32        2\n",
      "136       5\n",
      "Name: count, dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define which columns to compare the statistics of\n",
    "# Format: {col_name in dataset: column name used for printing results}\n",
    "comparison_columns = {\n",
    "    \"Savg_r\": \"Average Sharpness (acum)\",\n",
    "    \"Smax_r\": \"Peak Sharpness (acum)\",\n",
    "    \"Navg_r\": \"Average Loudness (sone)\",\n",
    "    \"Nmax_r\": \"Peak Loudness (sone)\",\n",
    "    \"Favg_r\": \"Average Fluctuation Strength (vacil)\",\n",
    "    \"Fmax_r\": \"Peak Fluctuation Strength (vacil)\",\n",
    "    \"Ravg_r\": \"Average Roughness (asper)\",\n",
    "    \"Rmax_r\": \"Peak Roughness (asper)\",\n",
    "    \"Tavg_r\": \"Average Tonality (tonality units)\",\n",
    "    \"Tmax_r\": \"Peak Tonality (tonality units)\",\n",
    "}\n",
    "# Define which columns from ARAUS_cleaned.csv to include in ARAUS_relevant.csv\n",
    "necessary_context = [\"participant\", \"soundscape\", \"masker\", \"time_taken\"]\n",
    "necessary_affective = [\"pleasant\", \"eventful\", \"chaotic\", \"vibrant\", \"uneventful\", \"calm\", \"annoying\", \"monotonous\"]\n",
    "relevant_data = data.loc[:, [*necessary_context, *necessary_affective, *list(comparison_columns.keys())]]\n",
    "\n",
    "# Write ARAUS csv with only relevant columns to new csv\n",
    "relevant_data.to_csv(\"datasets/ARAUS_relevant.csv\", index=False)\n",
    "\n",
    "\n",
    "# TO GROUP OUR DATA:\n",
    "# Combine participant strings for each soundscape and masker\n",
    "# Count number of participants combined for each soundscape and masker\n",
    "# Mean every numerical column (time taken, all afffective ratings, all acoustic features)\n",
    "\n",
    "# Prime a new column for counting the rows grouped together\n",
    "relevant_data.insert(0, \"merge_count\", 1)\n",
    "\n",
    "# Create aggregations dictionary to define aggregation logic for each column\n",
    "aggregations = {\n",
    "    \"participant\": lambda x: ', '.join(x),\n",
    "    \"merge_count\": \"sum\",\n",
    "}\n",
    "\n",
    "# Select only the columns that contain numerical data (and can be averaged)\n",
    "numeric_cols = list(relevant_data.select_dtypes(include=['Float64', 'Int64']).columns)\n",
    "\n",
    "for col_name in numeric_cols:\n",
    "    if col_name not in aggregations:\n",
    "        aggregations[col_name] = \"mean\"\n",
    "\n",
    "merged_data = relevant_data.groupby([\"soundscape\", \"masker\"]).agg(aggregations)\n",
    "print(f\"Data compressed from {len(relevant_data)} entries to {len(merged_data)} entries in the merged table.\")\n",
    "print(\"Average grouping size:\", merged_data['merge_count'].mean().round(3), \"soundscapes.\")\n",
    "print(\"Largest group merger count: {size:.1f} soundscapes\".format(size=merged_data['merge_count'].max()))\n",
    "print(\"\\nGroup size distribution:\")\n",
    "print(merged_data[\"merge_count\"].value_counts().sort_index(), \"\\n\")\n",
    "# merged_data.sort_values(by=[\"merge_count\"], ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15729, 21)\n",
      "(1572, 21)\n",
      "top 10% of pleasant & vibrant soundscapes\n",
      "{'mean': Savg_r     1.450685\n",
      "Smax_r     1.993258\n",
      "Navg_r    13.147601\n",
      "Nmax_r    20.868823\n",
      "Favg_r     0.025153\n",
      "Fmax_r     0.114328\n",
      "Ravg_r     0.027605\n",
      "Rmax_r     0.082020\n",
      "Tavg_r     0.216133\n",
      "Tmax_r     1.359875\n",
      "dtype: float64, 'standard deviation': Savg_r    0.272351\n",
      "Smax_r    0.444127\n",
      "Navg_r    5.219934\n",
      "Nmax_r    8.753789\n",
      "Favg_r    0.024501\n",
      "Fmax_r    0.065920\n",
      "Ravg_r    0.007553\n",
      "Rmax_r    0.053891\n",
      "Tavg_r    0.191927\n",
      "Tmax_r    0.848253\n",
      "dtype: float64, 'group size': 1572, 'variance': Savg_r     0.074175\n",
      "Smax_r     0.197249\n",
      "Navg_r    27.247715\n",
      "Nmax_r    76.628830\n",
      "Favg_r     0.000600\n",
      "Fmax_r     0.004346\n",
      "Ravg_r     0.000057\n",
      "Rmax_r     0.002904\n",
      "Tavg_r     0.036836\n",
      "Tmax_r     0.719533\n",
      "dtype: float64}\n",
      "{'mean': Savg_r     1.460358\n",
      "Smax_r     1.927224\n",
      "Navg_r    21.933377\n",
      "Nmax_r    35.732933\n",
      "Favg_r     0.027709\n",
      "Fmax_r     0.138783\n",
      "Ravg_r     0.036935\n",
      "Rmax_r     0.104105\n",
      "Tavg_r     0.279639\n",
      "Tmax_r     1.890757\n",
      "dtype: float64, 'standard deviation': Savg_r     0.254738\n",
      "Smax_r     0.389916\n",
      "Navg_r     6.747541\n",
      "Nmax_r    12.032342\n",
      "Favg_r     0.032840\n",
      "Fmax_r     0.058860\n",
      "Ravg_r     0.011193\n",
      "Rmax_r     0.059387\n",
      "Tavg_r     0.229347\n",
      "Tmax_r     1.160317\n",
      "dtype: float64, 'group size': 1572, 'variance': Savg_r      0.064891\n",
      "Smax_r      0.152035\n",
      "Navg_r     45.529316\n",
      "Nmax_r    144.777249\n",
      "Favg_r      0.001078\n",
      "Fmax_r      0.003464\n",
      "Ravg_r      0.000125\n",
      "Rmax_r      0.003527\n",
      "Tavg_r      0.052600\n",
      "Tmax_r      1.346335\n",
      "dtype: float64}\n"
     ]
    }
   ],
   "source": [
    "class Group:\n",
    "    def __init__(self, remarkable: bool, filter_cols: list, percentile: float, data: pd.DataFrame = merged_data):\n",
    "        self.remarkable = remarkable\n",
    "        self.filter_cols = filter_cols\n",
    "        self.percentile = percentile\n",
    "        self.data = data  # DataFrame to center analysis on\n",
    "        self.short_hand = self.create_short_hand()\n",
    "        self.descriptive_name = self.create_extended_name()\n",
    "        self.filtered_data = self.create_filtered_group()  # Store the filtered data as an attribute\n",
    "        self.statistics = self.calculate_statistics()\n",
    "    \n",
    "    def create_short_hand(self):\n",
    "        \"\"\"Creates a shorthand name for the group.\"\"\"\n",
    "        prefix = \"R_\" if self.remarkable else \"C_\"\n",
    "        return prefix + \"_\".join(self.filter_cols) + f\"_{int(100 * self.percentile)}\"\n",
    "\n",
    "    def create_extended_name(self):\n",
    "        \"\"\"Creates the descriptive name saying top/bottom {percentile} of *filter_cols.\"\"\"\n",
    "        prefix = \"top\" if self.percentile > 0.5 else \"bottom\"\n",
    "        readable_percentile = round(100 * (1 - self.percentile if self.percentile > 0.5 else self.percentile))\n",
    "        filters_description = \" & \".join(self.filter_cols)\n",
    "        return f\"{prefix} {readable_percentile}% of {filters_description} soundscapes\"\n",
    "\n",
    "    def create_filtered_group(self):\n",
    "        \"\"\"Filters the DataFrame based on provided filters and percentile, storing the result.\"\"\"\n",
    "        assert 0 <= self.percentile <= 1, \"Percentile must be between 0 and 1\"\n",
    "\n",
    "        ascend = self.percentile < 0.5\n",
    "        \n",
    "        # Sort and filter the DataFrame\n",
    "        group_data = self.data.sort_values(by=self.filter_cols + [\"merge_count\"], ascending=[ascend] * len(self.filter_cols) + [False])\n",
    "        slice_index = int(len(group_data) * (1-self.percentile)) if self.percentile > 0.5 else int(len(group_data) * self.percentile)\n",
    "        group_data = group_data.iloc[:slice_index, :]\n",
    "\n",
    "        if self.remarkable:\n",
    "            group_data.to_csv(f\"datasets/remarkable_groups/ARAUS_{self.short_hand}.csv\", index=False)\n",
    "        else:\n",
    "            group_data.to_csv(f\"datasets/comparison_groups/ARAUS_{self.short_hand}.csv\", index=False)\n",
    "\n",
    "        return group_data\n",
    "    \n",
    "    def calculate_statistics(self):\n",
    "        \"\"\"Calculate mean, standard deviation and size of all comparison columns in the group\"\"\"\n",
    "        data = self.filtered_data[comparison_columns.keys()]\n",
    "\n",
    "        return {\n",
    "            \"mean\": data.mean(),\n",
    "            \"standard deviation\": data.std(),\n",
    "            \"group size\": len(data),\n",
    "            \"variance\": data.var(),\n",
    "        }\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.descriptive_name\n",
    "\n",
    "# Remarkable groups\n",
    "# High percentile (.9) means the TOP 10% of the data\n",
    "# Order by which groups sorting will be prioritized (ex: if pleasant and vibrant listed, pleasant will be sorted first, then vibrant)\n",
    "remarkable_groups = [\n",
    "    Group(True, [\"pleasant\", \"vibrant\"], 0.9),\n",
    "    Group(True, [\"eventful\"], 0.9),\n",
    "    Group(True, [\"vibrant\"], 0.9),\n",
    "]\n",
    "\n",
    "print(merged_data.shape)\n",
    "print(remarkable_groups[0].filtered_data.shape)\n",
    "\n",
    "# Comparison groups\n",
    "# Low percentile (10) means BOTTOM 10% of the data\n",
    "comparison_groups = [\n",
    "    Group(False, [\"pleasant\"], 0.1),\n",
    "    Group(False, [\"eventful\"], 0.1),\n",
    "    Group(False, [\"vibrant\"], 0.1),\n",
    "]\n",
    "\n",
    "# Printing for testing\n",
    "print(remarkable_groups[0])\n",
    "print(remarkable_groups[0].statistics)\n",
    "print(comparison_groups[0].statistics)\n",
    "# print(remarkable_groups[0].filtered_data.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Group: top 10% of pleasant & vibrant soundscapes - size: 1572\n",
      "\n",
      "#### Average Sharpness (acum) statistics:\n",
      " - Mean: 1.4506850084817644\n",
      " - Standard deviation: 0.27235078086655745\n",
      "\n",
      "#### Peak Sharpness (acum) statistics:\n",
      " - Mean: 1.9932580576759966\n",
      " - Standard deviation: 0.44412717699776466\n",
      "\n",
      "#### Average Loudness (sone) statistics:\n",
      " - Mean: 13.147600720949958\n",
      " - Standard deviation: 5.219934397376341\n",
      "\n",
      "#### Peak Loudness (sone) statistics:\n",
      " - Mean: 20.868823155216287\n",
      " - Standard deviation: 8.75378945457842\n",
      "\n",
      "#### Average Fluctuation Strength (vacil) statistics:\n",
      " - Mean: 0.025153120229007637\n",
      " - Standard deviation: 0.02450052046121167\n",
      "\n",
      "#### Peak Fluctuation Strength (vacil) statistics:\n",
      " - Mean: 0.11432844571670907\n",
      " - Standard deviation: 0.06592045533687776\n",
      "\n",
      "#### Average Roughness (asper) statistics:\n",
      " - Mean: 0.027605460135708228\n",
      " - Standard deviation: 0.007553115922046375\n",
      "\n",
      "#### Peak Roughness (asper) statistics:\n",
      " - Mean: 0.08202003816793893\n",
      " - Standard deviation: 0.05389051943876032\n",
      "\n",
      "#### Average Tonality (tonality units) statistics:\n",
      " - Mean: 0.21613344783715008\n",
      " - Standard deviation: 0.19192700549850178\n",
      "\n",
      "#### Peak Tonality (tonality units) statistics:\n",
      " - Mean: 1.359875\n",
      " - Standard deviation: 0.8482531428251338\n",
      "\n",
      "-------------------------\n",
      "\n",
      "\n",
      "## Group: top 10% of eventful soundscapes - size: 1572\n",
      "\n",
      "#### Average Sharpness (acum) statistics:\n",
      " - Mean: 1.4450854537743851\n",
      " - Standard deviation: 0.21890241668543223\n",
      "\n",
      "#### Peak Sharpness (acum) statistics:\n",
      " - Mean: 1.9307241306191687\n",
      " - Standard deviation: 0.3788704270603215\n",
      "\n",
      "#### Average Loudness (sone) statistics:\n",
      " - Mean: 21.255954198473283\n",
      " - Standard deviation: 6.090750245306247\n",
      "\n",
      "#### Peak Loudness (sone) statistics:\n",
      " - Mean: 33.82826547921968\n",
      " - Standard deviation: 10.329054238244636\n",
      "\n",
      "#### Average Fluctuation Strength (vacil) statistics:\n",
      " - Mean: 0.02971293787107718\n",
      " - Standard deviation: 0.02946655419913384\n",
      "\n",
      "#### Peak Fluctuation Strength (vacil) statistics:\n",
      " - Mean: 0.13640461195928752\n",
      " - Standard deviation: 0.05846744903644517\n",
      "\n",
      "#### Average Roughness (asper) statistics:\n",
      " - Mean: 0.034679230279898214\n",
      " - Standard deviation: 0.008111606630457966\n",
      "\n",
      "#### Peak Roughness (asper) statistics:\n",
      " - Mean: 0.10114995759117897\n",
      " - Standard deviation: 0.06288891049258732\n",
      "\n",
      "#### Average Tonality (tonality units) statistics:\n",
      " - Mean: 0.3284729537743851\n",
      " - Standard deviation: 0.24151933540318288\n",
      "\n",
      "#### Peak Tonality (tonality units) statistics:\n",
      " - Mean: 2.022308630195081\n",
      " - Standard deviation: 1.1177824863683905\n",
      "\n",
      "-------------------------\n",
      "\n",
      "\n",
      "## Group: top 10% of vibrant soundscapes - size: 1572\n",
      "\n",
      "#### Average Sharpness (acum) statistics:\n",
      " - Mean: 1.4420900127226461\n",
      " - Standard deviation: 0.2314533381823809\n",
      "\n",
      "#### Peak Sharpness (acum) statistics:\n",
      " - Mean: 1.9551399491094148\n",
      " - Standard deviation: 0.411359360288929\n",
      "\n",
      "#### Average Loudness (sone) statistics:\n",
      " - Mean: 19.091240458015267\n",
      " - Standard deviation: 6.357589035943683\n",
      "\n",
      "#### Peak Loudness (sone) statistics:\n",
      " - Mean: 30.208645038167937\n",
      " - Standard deviation: 10.623592142804037\n",
      "\n",
      "#### Average Fluctuation Strength (vacil) statistics:\n",
      " - Mean: 0.030171404792196776\n",
      " - Standard deviation: 0.025341521442655255\n",
      "\n",
      "#### Peak Fluctuation Strength (vacil) statistics:\n",
      " - Mean: 0.13149331000848177\n",
      " - Standard deviation: 0.05695023362426804\n",
      "\n",
      "#### Average Roughness (asper) statistics:\n",
      " - Mean: 0.03325392281594571\n",
      " - Standard deviation: 0.008992004182024275\n",
      "\n",
      "#### Peak Roughness (asper) statistics:\n",
      " - Mean: 0.09964657548770145\n",
      " - Standard deviation: 0.06578077309272733\n",
      "\n",
      "#### Average Tonality (tonality units) statistics:\n",
      " - Mean: 0.30004176208651395\n",
      " - Standard deviation: 0.22418259592895737\n",
      "\n",
      "#### Peak Tonality (tonality units) statistics:\n",
      " - Mean: 1.8645388040712467\n",
      " - Standard deviation: 1.063074231183075\n",
      "\n",
      "-------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def print_group_statistics(*groups, printable_stats: list = [\"mean\", \"standard deviation\"]):\n",
    "    \"\"\"\n",
    "    Prints the statistics of a group in a formatted manner\n",
    "    \"\"\"\n",
    "    for group in groups:\n",
    "        print(f\"## Group: {group.descriptive_name} - size: {group.statistics['group size']}\\n\")\n",
    "        for col, col_label in comparison_columns.items():\n",
    "            print(f\"#### {col_label} statistics:\")\n",
    "            for stat_key in printable_stats:\n",
    "                label = stat_key.capitalize()\n",
    "                print(f\" - {label}: {group.statistics[stat_key].loc[col]}\")\n",
    "            print()\n",
    "        print(\"-------------------------\\n\\n\")\n",
    "\n",
    "# Print all remarkable_group statistics\n",
    "print_group_statistics(*remarkable_groups)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "def significance_test(group_one_data: pd.DataFrame, group_two_data: pd.DataFrame) -> tuple:\n",
    "    \"\"\"\n",
    "    Calculate the t-statistic and p-value for the two given groups.\n",
    "\n",
    "    Args:\n",
    "        group_one_data (pd.DataFrame): filtered_data from a Group object; group_one.filtered_data\n",
    "        group_two_data (pd.DataFrame): filtered_data from a different Group object to compare with\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple of two dictionaries containing t-statistics and p-values for each column.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initializing dictionaries for results\n",
    "    t_statistics = {}\n",
    "    p_values = {}\n",
    "\n",
    "    # Iterating over each statistic and calculating t-statistic and p-value\n",
    "    for col in comparison_columns.keys():\n",
    "        t_statistic, p_value = ttest_ind(\n",
    "            group_one_data[col], \n",
    "            group_two_data[col], \n",
    "            equal_var=False, \n",
    "            nan_policy=\"omit\"\n",
    "        )\n",
    "        t_statistics[col] = t_statistic\n",
    "        p_values[col] = p_value\n",
    "\n",
    "    return t_statistics, p_values\n",
    "\n",
    "#print(\"t-values\", significance_test(remarkable_groups[0], comparison_groups[0])[0])\n",
    "\n",
    "def verbose_compare_groups(\n",
    "    group_one: Group, \n",
    "    group_two: Group,\n",
    "    file,\n",
    "    comparison_columns: dict = comparison_columns, \n",
    "    test_p: float = 0.01, \n",
    "    include_insignificant: bool = True\n",
    "):\n",
    "    \"\"\"\n",
    "    Compares two groups, prints the comparison of their means, and calculates the t-test for significant difference in means.\n",
    "\n",
    "    Args:\n",
    "        group_one (Group): Group object with all information about the first group\n",
    "        group_two (Group): Group object with all information about the second group\n",
    "        comparison_columns (dict): Dictionary mapping data column keys to their descriptive labels.\n",
    "        file (Python I/O file object): Open file that can be written to \n",
    "        test_p (float): Value for testing significance of t-tests (typically 0.05 or 0.01)\n",
    "        include_insignificant (bool): Whether or not to include insignificant t-tests in the output\n",
    "    \"\"\"\n",
    "\n",
    "    # Retrieve group names and cache means\n",
    "    group_one_name, group_two_name = group_one.descriptive_name, group_two.descriptive_name\n",
    "    means_one = group_one.statistics['mean']\n",
    "    means_two = group_two.statistics['mean']\n",
    "    # Perform t-test and compare means\n",
    "    t_stats, p_values = significance_test(group_one.filtered_data, group_two.filtered_data)\n",
    "\n",
    "    # Begin file formatting\n",
    "    file.write(f\"## COMPARISON BETWEEN {group_one_name} AND {group_two_name}\\n\\n\")\n",
    "    file.write(\"[back to top](#table-of-contents)\\n\\n\")\n",
    "\n",
    "    # Prints a quick summary of statistical stats at the top\n",
    "    file.write(f\"*At a glace:*\\n\\n **STATISTICALLY SIGNIFICANT DIFFERENCES**: {[c for c,p in p_values.items() if p < test_p]}.\\n\")\n",
    "\n",
    "    underscore_counter = 0\n",
    "\n",
    "    # Write comparison of means and summary of t-tests\n",
    "    for col_key, label in comparison_columns.items():\n",
    "        group_one_stat = means_one[col_key]\n",
    "        group_two_stat = means_two[col_key]\n",
    "\n",
    "        higher_lower = \"**HIGHER**\" if group_one_stat > group_two_stat else \"**LOWER**\"\n",
    "        inverse_higher_lower = \"**LOWER**\" if higher_lower == \"**HIGHER**\" else \"**HIGHER**\"\n",
    "\n",
    "        file.write(f\"### PARAMETER: {label}\\n\")\n",
    "        file.write(f\"- *{group_one_name}* MEAN: {group_one_stat:.4f} - {higher_lower}\\n\")\n",
    "        file.write(f\"- *{group_two_name}* MEAN: {group_two_stat:.4f} - {inverse_higher_lower}\\n\")\n",
    "\n",
    "        significance = \"**STATISTICALLY SIGNIFICANT**\" if p_values[col_key] < test_p else \"NOT A STATISTICALLY SIGNIFICANT\"\n",
    "        if include_insignificant or p_values[col_key] < test_p:\n",
    "            file.write(f\"> {significance} DIFFERENCE WITH P={test_p}: p-value: {p_values[col_key]:.4f}, t-value: {t_stats[col_key]:.4f}\\n\\n\")\n",
    "\n",
    "        underscore_counter += 1\n",
    "        if underscore_counter % 2 == 0 and underscore_counter != 10:\n",
    "            file.write(\"-------------------\\n\")\n",
    "\n",
    "def create_tag_name(name: str):\n",
    "    \"\"\"\n",
    "    Add processing to a group.descriptive_name to make it a valid tag name for Markdown\n",
    "    \"\"\"\n",
    "    pre_tag = name.lower().split(' ')\n",
    "    return \"-\".join(pre_tag).replace(\"%\", \"\")\n",
    "\n",
    "\n",
    "# Compare all remarkable and comparison groups, output to total_comparisons.md file\n",
    "with open(\"t-test-outputs/total_comparisons.md\", \"w\") as file:\n",
    "    # Generate table of contents\n",
    "    file.write(\"# Table of Contents\\n\")\n",
    "    for r_group in remarkable_groups:\n",
    "        for c_group in comparison_groups:\n",
    "            file.write(f\"- [{r_group} vs. {c_group}](#comparison-between-{create_tag_name(r_group.descriptive_name)}-and-{create_tag_name(c_group.descriptive_name)})\\n\")\n",
    "    file.write(\"\\n\")\n",
    "    for r_group in remarkable_groups:\n",
    "        for c_group in comparison_groups:\n",
    "            verbose_compare_groups(\n",
    "                r_group,\n",
    "                c_group,\n",
    "                file\n",
    "            )\n",
    "        file.write(\"______________________________________</br></br></br></br>\\n\\n\")\n",
    "\n",
    "\n",
    "# Compare corresponding remarkable and comparison groups (pleasant vs. pleasant, vibrant vs. vibrant, etc.)\n",
    "if len(remarkable_groups) == len(comparison_groups):\n",
    "    with open(\"t-test-outputs/corresponding_comparisons.md\", \"w\") as file:\n",
    "        file.write(\"# Table of Contents\\n\")\n",
    "        for r_group, c_group in zip(remarkable_groups, comparison_groups):\n",
    "            file.write(f\"- [{r_group} vs. {c_group}](#comparison-between-{create_tag_name(r_group.descriptive_name)}-and-{create_tag_name(c_group.descriptive_name)})\\n\")\n",
    "        file.write(\"\\n\")\n",
    "        for r_group, c_group in zip(remarkable_groups, comparison_groups):\n",
    "            verbose_compare_groups(\n",
    "                r_group,\n",
    "                c_group,\n",
    "                file\n",
    "            )\n",
    "            file.write(\"______________________________________</br></br></br></br>\\n\\n\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T-Testing ARAUS\n",
    "\n",
    "We'll start by setting up our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "749 unique participants\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant</th>\n",
       "      <th>fold_r</th>\n",
       "      <th>soundscape</th>\n",
       "      <th>masker</th>\n",
       "      <th>smr</th>\n",
       "      <th>stimulus_index</th>\n",
       "      <th>time_taken</th>\n",
       "      <th>is_attention</th>\n",
       "      <th>pleasant</th>\n",
       "      <th>eventful</th>\n",
       "      <th>...</th>\n",
       "      <th>M04000_0_r</th>\n",
       "      <th>M05000_0_r</th>\n",
       "      <th>M06300_0_r</th>\n",
       "      <th>M08000_0_r</th>\n",
       "      <th>M10000_0_r</th>\n",
       "      <th>M12500_0_r</th>\n",
       "      <th>M16000_0_r</th>\n",
       "      <th>M20000_0_r</th>\n",
       "      <th>Leq_L_r</th>\n",
       "      <th>Leq_R_r</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ARAUS_00009</td>\n",
       "      <td>4</td>\n",
       "      <td>R0087_segment_binaural_44100_1.wav</td>\n",
       "      <td>silence_00004.wav</td>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>35.592</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>46.13</td>\n",
       "      <td>40.68</td>\n",
       "      <td>38.51</td>\n",
       "      <td>33.42</td>\n",
       "      <td>25.83</td>\n",
       "      <td>21.02</td>\n",
       "      <td>20.67</td>\n",
       "      <td>22.70</td>\n",
       "      <td>73.761966</td>\n",
       "      <td>75.353091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ARAUS_00021</td>\n",
       "      <td>1</td>\n",
       "      <td>R0081_segment_binaural_44100_2.wav</td>\n",
       "      <td>traffic_00029.wav</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>37.439</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>47.66</td>\n",
       "      <td>42.56</td>\n",
       "      <td>41.86</td>\n",
       "      <td>42.69</td>\n",
       "      <td>37.15</td>\n",
       "      <td>36.50</td>\n",
       "      <td>30.99</td>\n",
       "      <td>19.27</td>\n",
       "      <td>74.202644</td>\n",
       "      <td>73.493800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ARAUS_00021</td>\n",
       "      <td>1</td>\n",
       "      <td>R0046_segment_binaural_44100_2.wav</td>\n",
       "      <td>bird_00047.wav</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>37.833</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>43.73</td>\n",
       "      <td>39.67</td>\n",
       "      <td>35.29</td>\n",
       "      <td>33.46</td>\n",
       "      <td>27.51</td>\n",
       "      <td>19.27</td>\n",
       "      <td>18.67</td>\n",
       "      <td>12.37</td>\n",
       "      <td>67.246896</td>\n",
       "      <td>68.127026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ARAUS_00021</td>\n",
       "      <td>1</td>\n",
       "      <td>R0080_segment_binaural_44100_2.wav</td>\n",
       "      <td>traffic_00006.wav</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>33.782</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>44.57</td>\n",
       "      <td>43.30</td>\n",
       "      <td>43.81</td>\n",
       "      <td>36.82</td>\n",
       "      <td>31.24</td>\n",
       "      <td>28.05</td>\n",
       "      <td>23.03</td>\n",
       "      <td>17.66</td>\n",
       "      <td>67.395837</td>\n",
       "      <td>68.006605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ARAUS_00021</td>\n",
       "      <td>1</td>\n",
       "      <td>R0115_segment_binaural_44100_1.wav</td>\n",
       "      <td>bird_00059.wav</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>37.663</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>37.86</td>\n",
       "      <td>31.16</td>\n",
       "      <td>25.78</td>\n",
       "      <td>19.90</td>\n",
       "      <td>16.79</td>\n",
       "      <td>13.98</td>\n",
       "      <td>14.23</td>\n",
       "      <td>12.36</td>\n",
       "      <td>65.505416</td>\n",
       "      <td>66.575806</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 160 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   participant  fold_r                          soundscape             masker  \\\n",
       "0  ARAUS_00009       4  R0087_segment_binaural_44100_1.wav  silence_00004.wav   \n",
       "1  ARAUS_00021       1  R0081_segment_binaural_44100_2.wav  traffic_00029.wav   \n",
       "2  ARAUS_00021       1  R0046_segment_binaural_44100_2.wav     bird_00047.wav   \n",
       "3  ARAUS_00021       1  R0080_segment_binaural_44100_2.wav  traffic_00006.wav   \n",
       "4  ARAUS_00021       1  R0115_segment_binaural_44100_1.wav     bird_00059.wav   \n",
       "\n",
       "   smr  stimulus_index  time_taken  is_attention  pleasant  eventful  ...  \\\n",
       "0    3              28      35.592             0         5         5  ...   \n",
       "1    0               4      37.439             0         5         5  ...   \n",
       "2    3               8      37.833             0         5         5  ...   \n",
       "3    3              11      33.782             0         5         5  ...   \n",
       "4    0              12      37.663             0         5         5  ...   \n",
       "\n",
       "   M04000_0_r  M05000_0_r  M06300_0_r  M08000_0_r  M10000_0_r  M12500_0_r  \\\n",
       "0       46.13       40.68       38.51       33.42       25.83       21.02   \n",
       "1       47.66       42.56       41.86       42.69       37.15       36.50   \n",
       "2       43.73       39.67       35.29       33.46       27.51       19.27   \n",
       "3       44.57       43.30       43.81       36.82       31.24       28.05   \n",
       "4       37.86       31.16       25.78       19.90       16.79       13.98   \n",
       "\n",
       "   M16000_0_r  M20000_0_r    Leq_L_r    Leq_R_r  \n",
       "0       20.67       22.70  73.761966  75.353091  \n",
       "1       30.99       19.27  74.202644  73.493800  \n",
       "2       18.67       12.37  67.246896  68.127026  \n",
       "3       23.03       17.66  67.395837  68.006605  \n",
       "4       14.23       12.36  65.505416  66.575806  \n",
       "\n",
       "[5 rows x 160 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "file_path = \"datasets/ARAUS_precleaned.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "print(len(data[\"participant\"].unique()), \"unique participants\")\n",
    "\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we define all the values we will use for our analysis\n",
    "\n",
    "### DEFINITIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data compressed from 32232 entries to 15729 entries in the merged table.\n",
      "Average grouping size: 2.049 soundscapes.\n",
      "Largest group merger count: 136.0 soundscapes\n",
      "\n",
      "Group size distribution:\n",
      "merge_count\n",
      "1      7696\n",
      "2      4600\n",
      "3      3048\n",
      "4        32\n",
      "5       112\n",
      "19       16\n",
      "20      129\n",
      "21       82\n",
      "22        7\n",
      "32        2\n",
      "136       5\n",
      "Name: count, dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define which columns to compare the statistics of\n",
    "# Format: {col_name in dataset: column name used for printing results}\n",
    "comparison_columns = {\n",
    "    \"Savg_r\": \"Average Sharpness (acum)\",\n",
    "    \"Smax_r\": \"Peak Sharpness (acum)\",\n",
    "    \"Navg_r\": \"Average Loudness (sone)\",\n",
    "    \"Nmax_r\": \"Peak Loudness (sone)\",\n",
    "    \"Favg_r\": \"Average Fluctuation Strength (vacil)\",\n",
    "    \"Fmax_r\": \"Peak Fluctuation Strength (vacil)\",\n",
    "    \"Ravg_r\": \"Average Roughness (asper)\",\n",
    "    \"Rmax_r\": \"Peak Roughness (asper)\",\n",
    "    \"Tavg_r\": \"Average Tonality (tonality units)\",\n",
    "    \"Tmax_r\": \"Peak Tonality (tonality units)\",\n",
    "}\n",
    "# Define which columns from ARAUS_cleaned.csv to include in ARAUS_relevant.csv\n",
    "necessary_context = [\"participant\", \"soundscape\", \"masker\", \"time_taken\"]\n",
    "necessary_affective = [\"pleasant\", \"eventful\", \"chaotic\", \"vibrant\", \"uneventful\", \"calm\", \"annoying\", \"monotonous\"]\n",
    "relevant_data = data.loc[:, [*necessary_context, *necessary_affective, *list(comparison_columns.keys())]]\n",
    "\n",
    "# Write ARAUS csv with only relevant columns to new csv\n",
    "relevant_data.to_csv(\"datasets/ARAUS_relevant.csv\", index=False)\n",
    "\n",
    "\n",
    "# TO GROUP OUR DATA:\n",
    "# Combine participant strings for each soundscape and masker\n",
    "# Count number of participants combined for each soundscape and masker\n",
    "# Mean every numerical column (time taken, all afffective ratings, all acoustic features)\n",
    "\n",
    "# Prime a new column for counting the rows grouped together\n",
    "relevant_data.insert(0, \"merge_count\", 1)\n",
    "\n",
    "# Create aggregations dictionary to define aggregation logic for each column\n",
    "aggregations = {\n",
    "    \"participant\": lambda x: ', '.join(x),\n",
    "    \"merge_count\": \"sum\",\n",
    "}\n",
    "\n",
    "# Select only the columns that contain numerical data (and can be averaged)\n",
    "numeric_cols = list(relevant_data.select_dtypes(include=['Float64', 'Int64']).columns)\n",
    "\n",
    "for col_name in numeric_cols:\n",
    "    if col_name not in aggregations:\n",
    "        aggregations[col_name] = \"mean\"\n",
    "\n",
    "merged_data = relevant_data.groupby([\"soundscape\", \"masker\"]).agg(aggregations)\n",
    "print(f\"Data compressed from {len(relevant_data)} entries to {len(merged_data)} entries in the merged table.\")\n",
    "print(\"Average grouping size:\", merged_data['merge_count'].mean().round(3), \"soundscapes.\")\n",
    "print(\"Largest group merger count: {size:.1f} soundscapes\".format(size=merged_data['merge_count'].max()))\n",
    "print(\"\\nGroup size distribution:\")\n",
    "print(merged_data[\"merge_count\"].value_counts().sort_index(), \"\\n\")\n",
    "# merged_data.sort_values(by=[\"merge_count\"], ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 10% of pleasant & vibrant soundscapes\n",
      "{'mean': Savg_r     1.429374\n",
      "Smax_r     1.922855\n",
      "Navg_r    16.277099\n",
      "Nmax_r    26.021659\n",
      "Favg_r     0.022804\n",
      "Fmax_r     0.120233\n",
      "Ravg_r     0.030958\n",
      "Rmax_r     0.087595\n",
      "Tavg_r     0.221413\n",
      "Tmax_r     1.523287\n",
      "dtype: float64, 'standard deviation': Savg_r     0.247127\n",
      "Smax_r     0.402914\n",
      "Navg_r     6.127401\n",
      "Nmax_r    10.628502\n",
      "Favg_r     0.022162\n",
      "Fmax_r     0.057186\n",
      "Ravg_r     0.008846\n",
      "Rmax_r     0.055712\n",
      "Tavg_r     0.189651\n",
      "Tmax_r     0.976019\n",
      "dtype: float64, 'group size': 14156, 'variance': Savg_r      0.061072\n",
      "Smax_r      0.162340\n",
      "Navg_r     37.545046\n",
      "Nmax_r    112.965049\n",
      "Favg_r      0.000491\n",
      "Fmax_r      0.003270\n",
      "Ravg_r      0.000078\n",
      "Rmax_r      0.003104\n",
      "Tavg_r      0.035967\n",
      "Tmax_r      0.952614\n",
      "dtype: float64}\n"
     ]
    }
   ],
   "source": [
    "class Group:\n",
    "    def __init__(self, remarkable: bool, filter_cols: list, percentile: float, data: pd.DataFrame = merged_data, comparison_cols: dict = comparison_columns):\n",
    "        self.remarkable = remarkable\n",
    "        self.filter_cols = filter_cols\n",
    "        self.percentile = percentile\n",
    "        self.data = data  # DataFrame to center analysis on\n",
    "        self.comparison_columns = comparison_cols # Columns to use for comparison\n",
    "        self.short_hand = self.create_short_hand()\n",
    "        self.descriptive_name = self.create_extended_name()\n",
    "        self.filtered_data = self.create_filtered_group()  # Store the filtered data as an attribute\n",
    "        self.statistics = self.calculate_statistics()\n",
    "    \n",
    "    def create_short_hand(self):\n",
    "        \"\"\"Creates a shorthand name for the group.\"\"\"\n",
    "        prefix = \"R_\" if self.remarkable else \"C_\"\n",
    "        return prefix + \"_\".join(self.filter_cols) + f\"_{int(100 * self.percentile)}\"\n",
    "\n",
    "    def create_extended_name(self):\n",
    "        \"\"\"Creates the descriptive name saying top/bottom {percentile} of *filter_cols.\"\"\"\n",
    "        prefix = \"top\" if self.percentile > 0.5 else \"tottom\"\n",
    "        readable_percentile = round(100 * (1 - self.percentile if self.percentile > 0.5 else self.percentile))\n",
    "        filters_description = \" & \".join(self.filter_cols)\n",
    "        return f\"{prefix} {readable_percentile}% of {filters_description} soundscapes\"\n",
    "\n",
    "    def create_filtered_group(self):\n",
    "        \"\"\"Filters the DataFrame based on provided filters and percentile, storing the result.\"\"\"\n",
    "        assert 0 <= self.percentile <= 1, \"Percentile must be between 0 and 1\"\n",
    "\n",
    "        ascend = self.percentile < 0.5\n",
    "        \n",
    "        # Sort and filter the DataFrame\n",
    "        group_data = self.data.sort_values(by=self.filter_cols + [\"merge_count\"], ascending=[ascend] * len(self.filter_cols) + [False])\n",
    "        slice_index = int(len(group_data) * self.percentile)\n",
    "        group_data = group_data.iloc[:slice_index, :]\n",
    "\n",
    "        if self.remarkable:\n",
    "            group_data.to_csv(f\"datasets/remarkable_groups/ARAUS_{self.short_hand}.csv\", index=False)\n",
    "        else:\n",
    "            group_data.to_csv(f\"datasets/comparison_groups/ARAUS_{self.short_hand}.csv\", index=False)\n",
    "\n",
    "        return group_data\n",
    "    \n",
    "    def calculate_statistics(self):\n",
    "        \"\"\"Calculate mean, standard deviation and size of all comparison columns in the group\"\"\"\n",
    "        data = self.filtered_data[comparison_columns.keys()]\n",
    "\n",
    "        return {\n",
    "            \"mean\": data.mean(),\n",
    "            \"standard deviation\": data.std(),\n",
    "            \"group size\": len(data),\n",
    "            \"variance\": data.var(),\n",
    "        }\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.descriptive_name\n",
    "\n",
    "# Remarkable groups\n",
    "# High percentile (.9) means the TOP 10% of the data\n",
    "# Order by which groups sorting will be prioritized (ex: if pleasant and vibrant listed, pleasant will be sorted first, then vibrant)\n",
    "remarkable_groups = [\n",
    "    Group(True, [\"pleasant\", \"vibrant\"], 0.9),\n",
    "    Group(True, [\"eventful\"], 0.9),\n",
    "    Group(True, [\"vibrant\"], 0.9),\n",
    "]\n",
    "\n",
    "# Comparison groups\n",
    "# Low percentile (10) means BOTTOM 10% of the data\n",
    "comparison_groups = [\n",
    "    Group(False, [\"pleasant\"], 0.1),\n",
    "    Group(False, [\"eventful\"], 0.1),\n",
    "    Group(False, [\"vibrant\"], 0.1),\n",
    "]\n",
    "\n",
    "# Printing for testing\n",
    "print(remarkable_groups[0])\n",
    "print(remarkable_groups[0].statistics)\n",
    "print(comparison_groups[0].statistics)\n",
    "# print(remarkable_groups[0].filtered_data.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean': Savg_r     1.429374\n",
      "Smax_r     1.922855\n",
      "Navg_r    16.277099\n",
      "Nmax_r    26.021659\n",
      "Favg_r     0.022804\n",
      "Fmax_r     0.120233\n",
      "Ravg_r     0.030958\n",
      "Rmax_r     0.087595\n",
      "Tavg_r     0.221413\n",
      "Tmax_r     1.523287\n",
      "dtype: float64, 'standard deviation': Savg_r     0.247127\n",
      "Smax_r     0.402914\n",
      "Navg_r     6.127401\n",
      "Nmax_r    10.628502\n",
      "Favg_r     0.022162\n",
      "Fmax_r     0.057186\n",
      "Ravg_r     0.008846\n",
      "Rmax_r     0.055712\n",
      "Tavg_r     0.189651\n",
      "Tmax_r     0.976019\n",
      "dtype: float64, 'group size': 14156, 'variance': Savg_r      0.061072\n",
      "Smax_r      0.162340\n",
      "Navg_r     37.545046\n",
      "Nmax_r    112.965049\n",
      "Favg_r      0.000491\n",
      "Fmax_r      0.003270\n",
      "Ravg_r      0.000078\n",
      "Rmax_r      0.003104\n",
      "Tavg_r      0.035967\n",
      "Tmax_r      0.952614\n",
      "dtype: float64}\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'process_groups' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m col_interest_titles \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(comparison_columns\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# # Process all groups and store their statistics\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m remarkable_group_data \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_groups\u001b[49m(remarkable_groups, data, col_interest_titles)\n\u001b[1;32m     26\u001b[0m comparison_group_data \u001b[38;5;241m=\u001b[39m process_groups(comparison_groups, data, col_interest_titles)\n\u001b[1;32m     27\u001b[0m remarkable_group_stats \u001b[38;5;241m=\u001b[39m process_statistics(remarkable_group_data)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'process_groups' is not defined"
     ]
    }
   ],
   "source": [
    "col_interest_titles = list(comparison_columns.keys())\n",
    "\n",
    "# # Process all groups and store their statistics\n",
    "remarkable_group_data = process_groups(remarkable_groups, data, col_interest_titles)\n",
    "comparison_group_data = process_groups(comparison_groups, data, col_interest_titles)\n",
    "remarkable_group_stats = process_statistics(remarkable_group_data)\n",
    "comparison_group_stats = process_statistics(comparison_group_data)\n",
    "\n",
    "# print(remarkable_group_stats)\n",
    "# print(comparison_group_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_group(group_data: dict, group_name: str) -> dict:\n",
    "    \"\"\"\n",
    "    Selects a group from the given group_data dictionary (which contains at least 1 group) and returns \n",
    "    a dictionary containing only the selected group's statistics or data.\n",
    "\n",
    "    Works taking in both group_data and group_stats dictionaries.\n",
    "    \"\"\"\n",
    "    return {group_name: group_data[group_name]}\n",
    "\n",
    "def print_group_stats(group_stats: dict, comparison_columns: dict, printable_stats: list = [\"mean\", \"standard deviation\", \"group size\"]):\n",
    "    \"\"\"\n",
    "    Prints the statistics of each group in a formatted manner, using the labels from group_stats.\n",
    "    \"\"\"\n",
    "    for group_name, stats in group_stats.items():\n",
    "        group_size = stats[\"group size\"]\n",
    "        print(f\"### Group: {group_name} - size: {group_size}\")\n",
    "        for col_key, label in comparison_columns.items():\n",
    "            for stat_key, stat_value in stats.items():\n",
    "                if stat_key in printable_stats:\n",
    "                    # Check if stat_value is a DataFrame or series\n",
    "                    if isinstance(stat_value, (pd.DataFrame, pd.Series)):\n",
    "                        formatted_label = f\"{stat_key.capitalize()} {label}\"\n",
    "                        print(f\"    - **{formatted_label}**: {stat_value[col_key]:.4f}\")\n",
    "                    else:  # For non-DataFrame/Series statistics (like 'size')\n",
    "                        if stat_key != \"group size\":\n",
    "                            formatted_label = f\"{stat_key.capitalize()} of {group_name}\"\n",
    "                            print(f\"    - **{formatted_label}**: {stat_value}\")\n",
    "            print()\n",
    "\n",
    "        print(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "\n",
    "def significance_test(one_data: pd.DataFrame, two_data: pd.DataFrame) -> tuple:\n",
    "    \"\"\"\n",
    "    Calculate the t-statistic and p-value for the two given groups.\n",
    "\n",
    "    Args:\n",
    "        one_data (pd.DataFrame): Dataframe containing data for the first group (with only relevant columns).\n",
    "        two_data (pd.DataFrame): Dataframe containing data for the second group.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple of two dictionaries containing t-statistics and p-values for each column.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initializing dictionaries for results\n",
    "    t_statistics = {}\n",
    "    p_values = {}\n",
    "\n",
    "    # Iterating over each statistic and calculating t-statistic and p-value\n",
    "    for stat_name in one_data.columns:\n",
    "        t_statistic, p_value = ttest_ind(\n",
    "            one_data[stat_name], \n",
    "            two_data[stat_name], \n",
    "            equal_var=False, \n",
    "            nan_policy=\"omit\"\n",
    "        )\n",
    "        t_statistics[stat_name] = t_statistic\n",
    "        p_values[stat_name] = p_value\n",
    "\n",
    "    return t_statistics, p_values\n",
    "\n",
    "\n",
    "def verbose_compare_groups(\n",
    "    group_one_data: dict, \n",
    "    group_two_data: dict,\n",
    "    comparison_columns: dict, \n",
    "    file,\n",
    "    test_p: float = 0.01, \n",
    "    include_insignificant: bool = True\n",
    "):\n",
    "    \"\"\"\n",
    "    Compares two groups, prints the comparison of their means, and calculates the t-test for significant difference in means.\n",
    "\n",
    "    Args:\n",
    "        group_one_data (dict): Dictionary containing statistics for the first group.\n",
    "        group_two_data (dict): Dictionary containing statistics for the second group.\n",
    "        comparison_columns (dict): Dictionary mapping data column keys to their descriptive labels.\n",
    "        file (Python I/O file object): Open file that can be written to \n",
    "        test_p (float): Value for testing significance of t-tests (typically 0.05 or 0.01)\n",
    "        include_insignificant (bool): Whether or not to include insignificant t-tests in the output\n",
    "    \"\"\"\n",
    "\n",
    "    # Retrieve group names\n",
    "    group_one_name, group_two_name = list(group_one_data.keys())[0], list(group_two_data.keys())[0]\n",
    "    one_data, two_data = list(group_one_data.values())[0], list(group_two_data.values())[0]\n",
    "\n",
    "    file.write(f\"## COMPARISON BETWEEN {group_one_name} AND {group_two_name} GROUPS\\n\\n\")\n",
    "\n",
    "    means_one = calculate_statistics(one_data)['mean']\n",
    "    means_two = calculate_statistics(two_data)['mean']\n",
    "\n",
    "    # Perform t-test and compare means\n",
    "    t_stats, p_values = significance_test(one_data, two_data)\n",
    "\n",
    "    underscore_counter = 0\n",
    "\n",
    "    # Write comparison of means and summary of t-tests\n",
    "    for col_key, label in comparison_columns.items():\n",
    "        group_one_stat = means_one[col_key]\n",
    "        group_two_stat = means_two[col_key]\n",
    "\n",
    "        higher_lower = \"**HIGHER**\" if group_one_stat > group_two_stat else \"**LOWER**\"\n",
    "        inverse_higher_lower = \"**LOWER**\" if higher_lower == \"**HIGHER**\" else \"**HIGHER**\"\n",
    "\n",
    "        file.write(f\"### PARAMETER: {label}\\n\")\n",
    "        file.write(f\"- *{group_one_name}* MEAN: {group_one_stat:.4f} - {higher_lower}\\n\")\n",
    "        file.write(f\"- *{group_two_name}* MEAN: {group_two_stat:.4f} - {inverse_higher_lower}\\n\")\n",
    "\n",
    "        significance = \"**STATISTICALLY SIGNIFICANT**\" if p_values[col_key] < test_p else \"NOT A STATISTICALLY SIGNIFICANT\"\n",
    "        if include_insignificant or p_values[col_key] < test_p:\n",
    "            file.write(f\"> {significance} DIFFERENCE WITH P={test_p}: p-value: {p_values[col_key]:.4f}, t-value: {t_stats[col_key]:.4f}\\n\\n\")\n",
    "\n",
    "        underscore_counter += 1\n",
    "        if underscore_counter % 2 == 0 and underscore_counter != 10:\n",
    "            file.write(\"-------------------\\n\")\n",
    "\n",
    "\n",
    "# Compare all remarkable and comparison groups, output to total_comparisons.md file\n",
    "with open(\"t-test-outputs/total_comparisons.md\", \"w\") as file:\n",
    "    # Generate table of contents\n",
    "    file.write(\"# Table of Contents\\n\")\n",
    "    for r_group in remarkable_group_data:\n",
    "        for c_group in comparison_group_data:\n",
    "            file.write(f\"- [{r_group} vs. {c_group}](#comparison-between-{r_group.lower()}-and-{c_group.lower()}-groups)\\n\")\n",
    "    file.write(\"\\n\")\n",
    "    for r_group in remarkable_group_data:\n",
    "        for c_group in comparison_group_data:\n",
    "            verbose_compare_groups(\n",
    "                select_group(remarkable_group_data, r_group),\n",
    "                select_group(comparison_group_data, c_group),\n",
    "                comparison_columns,\n",
    "                file\n",
    "            )\n",
    "        file.write(\"______________________________________</br></br></br></br>\\n\\n\")\n",
    "\n",
    "\n",
    "# Compare corresponding remarkable and comparison groups (pleasant vs. pleasant, vibrant vs. vibrant, etc.)\n",
    "with open(\"t-test-outputs/corresponding_comparisons.md\", \"w\") as file:\n",
    "    file.write(\"# Table of Contents\\n\")\n",
    "    for r_group, c_group in zip(remarkable_group_data, comparison_group_data):\n",
    "        file.write(f\"- [{r_group} vs. {c_group}](#comparison-between-{r_group.lower()}-and-{c_group.lower()}-groups)\\n\")\n",
    "    file.write(\"\\n\")\n",
    "    for r_group, c_group in zip(remarkable_group_data, comparison_group_data):\n",
    "        verbose_compare_groups(\n",
    "            select_group(remarkable_group_data, r_group),\n",
    "            select_group(comparison_group_data, c_group),\n",
    "            comparison_columns,\n",
    "            file\n",
    "        )\n",
    "        file.write(\"______________________________________</br></br></br></br>\\n\\n\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
